import torch
import torch.nn.functional as F
from model import GPT
import argparse
import json
import re
import os
import sys
from tokenizer import Tokenizer

# Hyperparameters (must match training)
n_embd = 384
n_head = 6
n_layer = 6
block_size = 1024
dropout = 0.1
device = 'cuda' if torch.cuda.is_available() else 'cpu'

def format_hex(hex_str):
    # Formats "0A1F0000" -> "0A 1F 00 00"
    # Remove any existing spaces first just in case
    clean_hex = hex_str.replace(" ", "")
    return " ".join(clean_hex[i:i+2] for i in range(0, len(clean_hex), 2))

def parse_generated_text(text):
    # Expected format: <BOS> PROTOCOL:NEC ADDRESS:04000000 [BTN_POWER]:0A1F0000 [BTN_VOL_UP]:...
    # We need to extract [BTN_NAME]:CODE pairs
    
    # The new tokenizer outputs tokens directly. 
    # [BTN_...], ':', '0A', '1F', '00', '00' ...
    # So the text will be a concatenation of these.
    
    # Regex needs to be robust to spaces if tokenizer adds them (it doesn't by default).
    # But let's assume raw concatenation: "[BTN_POWER]:0A1F0000"
    
    pattern = r'(\[BTN_[^\]]+\]):([0-9A-Fa-f]+)'
    matches = re.findall(pattern, text)
    return matches

def main():
    parser = argparse.ArgumentParser(description="Generate IR codes using trained NanoGPT model.")
    parser.add_argument('--protocol', type=str, required=True, help='IR Protocol (e.g., NEC)')
    parser.add_argument('--address', type=str, required=True, help='Device Address (hex, e.g., 04000000)')
    parser.add_argument('--known_btn', type=str, required=True, help='Known Button Name (e.g., POWER)')
    parser.add_argument('--known_code', type=str, required=True, help='Known Button Code (hex, e.g., 0A1F0000)')
    parser.add_argument('--model_path', type=str, default='model.pt', help='Path to trained model checkpoint')
    parser.add_argument('--vocab_path', type=str, default='vocab.json', help='Path to vocabulary file')
    parser.add_argument('--output', type=str, default='generated.ir', help='Output file path')
    parser.add_argument('--temperature', type=float, default=0.8, help='Sampling temperature')
    parser.add_argument('--top_k', type=int, default=40, help='Top-K sampling')
    
    args = parser.parse_args()

    # 1. Load Vocab
    tok = Tokenizer(args.vocab_path)
    if not tok.load_vocab():
        sys.exit(1)
    vocab_size = len(tok.stoi)

    # 2. Load Model
    if not os.path.exists(args.model_path):
        print(f"Error: {args.model_path} not found.")
        sys.exit(1)

    model = GPT(vocab_size, n_embd, n_head, n_layer, block_size, dropout)
    # map_location='cpu' is safer if user doesn't have cuda, though we set device above
    model.load_state_dict(torch.load(args.model_path, map_location=device))
    model.to(device)
    model.eval()

    # 3. Construct Prompt
    # Normalize inputs
    protocol = args.protocol
    address = args.address
    known_btn_name = args.known_btn.upper()
    known_btn_token = f"[BTN_{known_btn_name}]"
    known_code = args.known_code

    # Prompt: <BOS> PROTOCOL:{protocol} ADDRESS:{address} [BTN_{known_btn}]:{known_code}
    # Note: We rely on the model to continue generating [BTN_...]:...
    prompt_str = f"<BOS> PROTOCOL:{protocol} ADDRESS:{address} {known_btn_token}:{known_code}"
    
    print(f"Prompt: {prompt_str}")

    # 4. Encode
    input_ids = tok.encode(prompt_str)
    if not input_ids:
        print("Error: Encoding resulted in empty sequence. Check your inputs and vocabulary.")
        sys.exit(1)
        
    x = torch.tensor(input_ids, dtype=torch.long, device=device)[None, ...] # (1, T)

    # 5. Generate
    print("Generating...")
    max_new_tokens = 500 # reasonable limit for an IR file
    
    with torch.no_grad():
        output_ids = model.generate(x, max_new_tokens, temperature=args.temperature, top_k=args.top_k)
    
    # 6. Decode
    generated_text = tok.decode(output_ids[0].tolist())
    
    # Trim to <EOS> if present
    if "<EOS>" in generated_text:
        final_text = generated_text.split("<EOS>")[0]
    else:
        final_text = generated_text
        
    print("Generation complete.")
    
    # 7. Parse & Export
    matches = parse_generated_text(final_text)
    
    if not matches:
        print("No valid buttons found in generation.")
    
    # Write to .ir file
    with open(args.output, 'w') as f:
        f.write("Filetype: IR signals file\n")
        f.write("Version: 1\n")
        f.write("# Generated by AI\n")
        
        for btn_token, code in matches:
            # Extract clean name: [BTN_POWER] -> POWER
            clean_name = btn_token.replace("[BTN_", "").replace("]", "")
            
            # Format hex
            formatted_address = format_hex(address)
            formatted_code = format_hex(code)
            
            f.write(f"name: {clean_name}\n")
            f.write("type: parsed\n")
            f.write(f"protocol: {protocol}\n")
            f.write(f"address: {formatted_address}\n")
            f.write(f"command: {formatted_code}\n")
            f.write("#\n")

    print(f"Saved to {args.output}")

if __name__ == "__main__":
    main()
